# Step 1: Install spaCy (if not already installed)
!pip install -U spacy

# Step 2: Download spaCy English language model
!python -m spacy download en_core_web_sm

# Step 3: Import libraries and load spaCy model
import spacy
from spacy import displacy

# Load the English NLP model
nlp = spacy.load("en_core_web_sm")

# Step 4: Load or define a small dataset (news articles / Wikipedia snippets)
# You can replace these with actual dataset lines if needed
texts = [
    "Apple Inc. is planning to open a new office in Seattle in 2024.",
    "Barack Obama was born on August 4, 1961 in Honolulu, Hawaii.",
    "Google was founded by Larry Page and Sergey Brin while they were Ph.D. students at Stanford University.",
    "The World Health Organization declared COVID-19 a pandemic on March 11, 2020.",
    "Elon Musk's SpaceX successfully launched the Falcon Heavy rocket from Cape Canaveral."
]

# Step 5: Perform Named Entity Recognition on each text
for i, text in enumerate(texts):
    print(f"\n--- Document {i+1} ---")
    doc = nlp(text)
    for ent in doc.ents:
        print(f"{ent.text} ({ent.label_})")

# Step 6: Visualize named entities using displaCy
from IPython.core.display import display, HTML
# Visualize one example text
doc = nlp(texts[3])
# Render in Jupyter (Colab) notebook
displacy.render(doc, style="ent", jupyter=True)



--------------------------------------------------------------------------------------------------------------



3. Perform Named Entity Recognition:

Python

# Step 5: Perform Named Entity Recognition on each text
for i, text in enumerate(texts): # Loop through each text in the list
    print(f"\n--- Document {i+1} ---") # Print a header for the current document
    doc = nlp(text) # Process the text using the spaCy model
    # Iterate through the named entities found in the processed document
    for ent in doc.ents:
        # Print the entity's text and its predicted label
        print(f"{ent.text} ({ent.label_})")
Concept: Named Entity Recognition (NER): NER is a subtask of information extraction that seeks to locate and classify named entities in text into1 predefined categories such as person names, organizations, locations, medical codes, time expressions, quantities, monetary values, percentages, etc. Â  
1.
codesy.sellfy.store
codesy.sellfy.store
for i, text in enumerate(texts):: This loop iterates through each string (text) in the texts list, providing both the index (i, starting from 0) and the text content.
doc = nlp(text): This is where spaCy's processing pipeline is run on the current text. The en_core_web_sm model includes a NER component. When nlp(text) is executed, the NER component analyzes the text and identifies potential named entities, storing them in the resulting Doc object.
for ent in doc.ents:: The doc object has an attribute .ents, which is a list-like collection of all the named entity spans found in the text. This loop iterates through each identified entity span (ent).
print(f"{ent.text} ({ent.label_})"): For each entity found (ent), it prints:
ent.text: The actual text string of the entity (e.g., "Apple Inc.", "Seattle", "2024").
ent.label_: The predicted category or label for the entity (e.g., "ORG" for organization, "GPE" for geopolitical entity, "DATE").
4. Visualize Named Entities:

Python

# Step 6: Visualize named entities using displaCy
# This import is often needed in environments like Jupyter notebooks to display HTML output correctly
from IPython.core.display import display, HTML

# Process one example text again specifically for visualization
doc = nlp(texts[3]) # Choosing the 4th document (index 3) for visualization

# Render the processed document using displaCy for named entity visualization
# style="ent" indicates NER visualization
# jupyter=True tells displaCy to output HTML suitable for notebooks (like Colab or Jupyter)
displacy.render(doc, style="ent", jupyter=True)
Purpose: displacy provides a convenient way to visualize the results of spaCy's processing directly within a notebook environment. For NER, it highlights the entity spans in the original text and labels them with their predicted category.
from IPython.core.display import display, HTML: This line imports tools often needed in interactive environments (like Jupyter notebooks or Google Colab) to correctly render the HTML output generated by displacy.
doc = nlp(texts[3]): Processes the text from the 4th document (texts[3]) using the nlp pipeline again. This is done to get a Doc object specifically for the visualization step.
displacy.render(doc, style="ent", jupyter=True):
doc: The processed spaCy Doc object containing the entities to be visualized.
style="ent": This argument tells displacy to render the output in the "entity" style, which is designed specifically for visualizing named entities.
jupyter=True: This argument instructs displacy to generate HTML output suitable for embedding directly into a Jupyter or Colab notebook cell. If you were running this in a standard Python script, you might use displacy.serve() instead to launch a small web server displaying the visualization.